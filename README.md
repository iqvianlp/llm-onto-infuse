## Ontological knowledge infusion in embedding-Large Language Models

The code of this repository implements a novel approach to improve an embedding-Large Language 
Model (embedding-LLM) of interest by infusing the knowledge formalized by a reference ontology: ontological 
knowledge infusion aims at boosting the ability of the considered embedding-LLM to effectively model 
the knowledge domain described by the infused ontology.

The ontological knowledge infusion approach
is described into details by the article 
[Towards Ontology-Enhanced Representation Learning for Large Language Models](https://arxiv.org/abs/2405.20527).

Hereinafter we describe the procedure to follow to infuse the disease knowledge formalized by the 
[disease ontology MONDO](https://mondo.monarchinitiative.org/) in four widespread embedding-LLMs 
and evaluate the ontology-enhanced embedding-LLMs against two widespread sentence-similarity 
datasets: [BIOSSES](https://huggingface.co/datasets/biosses) (biomedical domain) and the five test sets of SemEval Sentence Similarity challenges
released yearly of [2012](https://huggingface.co/datasets/mteb/sts12-sts), [2013](https://huggingface.co/datasets/mteb/sts13-sts),
[2014](https://huggingface.co/datasets/mteb/sts14-sts), [2015](https://huggingface.co/datasets/mteb/sts15-sts), 
[2016](https://huggingface.co/datasets/mteb/sts16-sts).
  
### 1) Set-up environment
- Create and activate a virtual environment based on Python 3.10.x.
- Clone the repository, set the repo-folder as the working directory and install python requirements: `pip install -r requirements.txt`
- Create a resource-folder - e.g. `RESOURCE_FOLDER` where all the data / models generated to support 
and evaluate ontological knowledge infusion will be stored: inside the resource-folder create three sub-folders 
with the following names: `ONTO_FUSE_SYNTH_DATA`, `CHROMA_DB`, `EVAL_RESULT`.
- Modify the line 3 of the file [constant_config.py](constant_config.py) by setting the value of `BASE_DATA_FOLDER_PATH` 
equal to the absolute local path of the resource-folder. The python scripts included in this repository 
should be able to read files from and write files to the resorce-folder.

### 2) Preload MONDO ontology
Run the [onto/load.py](onto/load.py) script: in the resource-folder a MONDO ontology pickle object file 
exploited to store the contents of the ontology to support ontological knowledge infusion, will be 
created.

### 3) Generate synthetic definitions of MONDO ontology concepts
- Add your OpenAI access credentials to prompt GPT-3.5-turbo in the module [synth_data_gen/constants.py](synth_data_gen/constants.py). 
The module [synth_data_gen/prompt_openai.py](synth_data_gen/prompt_openai.py) wraps interactions with OpenAI GPT-3.5-turbo model.
- Run [synth_data_gen/generate_synth_data.py](synth_data_gen/generate_synth_data.py) script: this script will generate a synthetic 
concept definition from each synonym of each concept of the MONDO ontology. The synthetic concept 
definitions generated by running this script are stored in a CSV file inside the `ONTO_FUSE_SYNTH_DATA` 
folder (that in turns is a sub-folder of the resource-folder).

### 4) Perform ontological knowledge infusion by fine-tuning embedding-LLMs by a contrastive objective
Run [llm_train/train_and_evaluate_onto_knowldge_infusion.py](llm_train/train_and_evaluate_onto_knowldge_infusion.py) 
by providing the following two command line arguments:
- **ARGUMENT 1**: embedding-LLM base model identifier, to perform ontological knowledge infusion 
on such embedding-LLM. One of: sapbert_cls, pubmedbert_mean, pubmedbert_cls, gist, gtebase.
- **ARGUMENT 2**: name of the CSV file with synthetic definitions generated by running the script 
[synth_data_gen/generate_synth_data.py](synth_data_gen/generate_synth_data.py), as described at 
step 3 and stored in the `ONTO_FUSE_SYNTH_DATA` folder (that is a sub-folder of the resource-folder).

This script will perform the following actions:
- read real definitions of concepts from the MONDO ontology, together with synthetically generated ones
  (as described at step 3)
- ontology-driven generation of positive pairs of definitions by synonym substitution
- ontology-driven generation of hard-negative pairs of definitions by: (i) indexing all definitions 
in a collection of the [Chroma DB embedding database](https://www.trychroma.com/); (ii) identifying 
for each definition the associated hard-negative one(s), relying on the is-a relations specified by 
the MONDO ontology
- infuse disease knowledge from the MONDO ontology in the embedding-LLM selected through command-line 
**ARGUMENT 1**: this is obtained by relying on a contrastive learning framework relying on 
InfoNCE loss (for more details refer the [paper on ontological knowledge infusion](https://arxiv.org/abs/2405.20527)). 
- While the ontological knowledge infusion process proceeds, the selected embedding-LLM is 
evaluated at regular intervals: evaluation is performed against two widespread sentence-similarity 
datasets: [BIOSSES](https://huggingface.co/datasets/biosses) (biomedical domain) and the five test sets of SemEval Sentence Similarity challenges
released yearly of [2012](https://huggingface.co/datasets/mteb/sts12-sts), [2013](https://huggingface.co/datasets/mteb/sts13-sts),
[2014](https://huggingface.co/datasets/mteb/sts14-sts), [2015](https://huggingface.co/datasets/mteb/sts15-sts), 
[2016](https://huggingface.co/datasets/mteb/sts16-sts). Evaluation results are stored in .eval text 
files in the `EVAL_RESULT` folder (that is a sub-folder of the resource-folder).



### Reference publication 
The code shared by this repository implements the ontological knowledge infusion approach presented
by the following publication:
- **TITLE**: Towards Ontology-Enhanced Representation Learning for Large Language Models
- **AUTHORS**: Francesco Ronzano and Jay Nanavati
- **AFFILIATION**: IQVIA
- **ARXIV LINK**: [https://arxiv.org/abs/2405.20527](https://arxiv.org/abs/2405.20527)
- **DATE**: 30 May 2024

