import hashlib
import io
from datetime import datetime
from pathlib import Path

__import__('pysqlite3')
import sys

sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

import os
import pickle
import random

from tabulate import tabulate

import torch
from sentence_transformers import SentenceTransformer, losses, InputExample, models
from torch.utils.data import DataLoader
from tqdm import tqdm

import constant_config
from llm_train.evaluator.evaluation_utils import get_STS_evaluator, EVALUATORS_STS, evaluate_sts_datasets
from llm_train.sample_select.negative_pairs import generate_hard_negative_pairs
from llm_train.sample_select.positive_pairs import generate_positive_pairs_by_synonym_substitution
from llm_train.train_data_loader import load_definition_spreadsheet
from onto.load import load_mondo_onto_dictionary, get_ancestors_of, get_descendants_of, get_siblings_of

base_data_csv_path = constant_config.SYNTHETIC_DATA_OUTPUT_FOLDER_PATH
base_path_pickle = constant_config.BASE_DATA_FOLDER_PATH
config_dict = dict()


def generate_pairs(real_synth_definitions, ontology_dict, st_transformer_model, cdb_name):
    """
    Generate for each concept definitions the associated positive pairs by synonym substitution as well as the
    negative pairs that are texts with an embedding that is: (i) most similar to the embedding of concept definition;
    (ii) describing a concept that is not ancestor or descendant of the considered concept
    :param real_synth_definitions: dictionary of real definitions and synthetic definitions generated by GPT-3.5-turbo
    :param ontology_dict: the onto-dictionary providing information of (MONDO) ontology concepts
    :param st_transformer_model: sentence transformer model to exploit to generate text embeddings
    :param cdb_name: name of the Chroma DB embedding database where to store all concept definitions, useful to
                     support embedding-based nearest neighbors searches of texts
    :return:
    """

    # Full local paths of the pickle object files where to store positive and hard negative pairs for each concept
    # definition
    positive_pairs_path_pickle = os.path.join(constant_config.BASE_DATA_FOLDER_PATH,
                                              f'exp_1__{chroma_db_name}__positive_pairs.pk')
    negative_pairs_path_pickle = os.path.join(constant_config.BASE_DATA_FOLDER_PATH,
                                              f'exp_1__{chroma_db_name}__negative_pairs.pk')

    # POSITIVE TEXT PAIRS GENERATION: synonym substitution
    if os.path.isfile(positive_pairs_path_pickle):
        print(f"Loading positive_pairs from pickle file {positive_pairs_path_pickle}...")
        file = open(positive_pairs_path_pickle, 'rb')
        synthetic_defs__positive_pairs = pickle.load(file)
        file.close()
    else:
        print(f"Loading positive_pairs and then storing to pickle file {positive_pairs_path_pickle}...")
        synthetic_defs__positive_pairs = generate_positive_pairs_by_synonym_substitution(real_synth_definitions,
                                                                                         ontology_dict)
        # Serialize and store positive text pairs as pickle object file
        file = open(positive_pairs_path_pickle, 'wb')
        pickle.dump(synthetic_defs__positive_pairs, file)
        file.close()

    # NEGATIVE TEXT PAIRS GENERATION: hard negatives
    if os.path.isfile(negative_pairs_path_pickle):
        print(f"Loading negative_pairs from pickle file {negative_pairs_path_pickle}...")
        file = open(negative_pairs_path_pickle, 'rb')
        synthetic_defs__hard_negatives = pickle.load(file)
        file.close()
    else:
        print(f"Loading negative_pairs and then storing to pickle file {negative_pairs_path_pickle}...")
        synthetic_defs__hard_negatives = generate_hard_negative_pairs(synthetic_defs__positive_pairs, ontology_dict,
                                                                      st_transformer_model,
                                                                      chromadb_coll_name=cdb_name)
        # Serialize and store negative text pairs as pickle object file
        file = open(negative_pairs_path_pickle, 'wb')
        pickle.dump(synthetic_defs__hard_negatives, file)
        file.close()

    print(f"Loaded positive and negative fine-tuning pairs.")

    return synthetic_defs__positive_pairs, synthetic_defs__hard_negatives


def generate_training_examples(pos_pairs, neg_pairs):
    """
    Given the positive and (hard-)negative pairs, generate a list of training examples for ontological knowledge
    infusion (i.e. instances of the InputExample class)
    :param pos_pairs: generated by the method llm_train.sample_select.generate_positive_pairs_by_synonym_substitution
    :param neg_pairs: generated by the method llm_train.sample_select.generate_hard_negative_pairs
    :return: list of training examples for ontological knowledge infusion (i.e. instances of the InputExample class)
    """
    text_hash_list = {hashlib.md5(el.encode("utf")).hexdigest(): (idx, el) for idx, el in enumerate(neg_pairs['text_list'])}
    considered_text_hash = dict()

    # Variables with stats on generated training samples
    stat_with_hard_neg = 0
    stat_no_hard_neg = 0
    stat_hard_neg_siblings = 0
    stat_hard_neg_other = 0
    stat_cid_with_train_ex = set()
    stat_cid_with_neg_train_ex = set()
    stat_printed_info = False

    train_samples_by_cid = dict()
    for cid, positive_pair_dict in tqdm(pos_pairs.items(), desc=f"Loading all definitions / texts associated with each concept..."):

        # print(f"CONCEPT ID: {cid}")

        if cid not in train_samples_by_cid:
            train_samples_by_cid[cid] = dict()
            train_samples_by_cid[cid]['ancestors'] = get_ancestors_of(onto_dict, cid)
            train_samples_by_cid[cid]['descendants'] = get_descendants_of(onto_dict, cid)
            train_samples_by_cid[cid]['siblings'] = get_siblings_of(onto_dict, cid)
            train_samples_by_cid[cid]['train_ex_list'] = list()
            stat_printed_info = False

        for text_hash, text_dict in positive_pair_dict.items():

            if 'txt' in text_dict and isinstance(text_dict['txt'], str) and len(text_dict['txt'].strip()) > 0 and \
                    'syn_replace' in text_dict and isinstance(text_dict['syn_replace'], set) and \
                    len(text_dict['syn_replace']) > 0:

                input_ex_anchor = text_dict['txt'].strip()
                input_ex_anchor_hash = text_hash
                # print(f"       --> ANCHOR TEXT: '{input_ex_anchor}'")

                # Avoid duplication
                if input_ex_anchor_hash not in considered_text_hash:
                    considered_text_hash[input_ex_anchor_hash] = dict()
                    considered_text_hash[input_ex_anchor_hash]['pos'] = set()
                    considered_text_hash[input_ex_anchor_hash]['neg'] = set()

                # Identify positive sentence
                for input_ex_positive in text_dict['syn_replace']:

                    input_ex_positive_hash = hashlib.md5(input_ex_positive.encode("utf")).hexdigest()

                    # Avoid duplication, consider the positive only if not already associated to the anchor
                    if input_ex_positive_hash not in considered_text_hash[input_ex_anchor_hash]['pos']:
                        considered_text_hash[input_ex_anchor_hash]['pos'].add(input_ex_positive_hash)
                        # print(f"       --> POSITIVE TEXT: '{input_ex_positive}'")

                        # Retrieve hard-negative associated to the anchor sentence input_ex_anchor
                        # (with input_ex_anchor_hash) that describes the concept with id equal to cid
                        input_ex_anchor_text_hash_list_element = text_hash_list[input_ex_anchor_hash] if input_ex_anchor_hash in text_hash_list else None
                        hard_negatives_dict = neg_pairs['hard_negatives_by_concept_id'][cid][input_ex_anchor_text_hash_list_element[0]] if cid in neg_pairs[ 'hard_negatives_by_concept_id'] and input_ex_anchor_text_hash_list_element[0] in neg_pairs['hard_negatives_by_concept_id'][cid] else None

                        # Select as hard negative 'other'
                        input_ex_hard_negative = None
                        input_ex_hard_negative_cid = None
                        is_input_ex_hard_negative_from_siblings = False
                        if isinstance(hard_negatives_dict, dict):
                            if len(considered_text_hash[input_ex_anchor_hash]['neg']) == len( hard_negatives_dict['other']):
                                considered_text_hash[input_ex_anchor_hash]['neg'] = set()

                            idx_list = list( range(0, len(hard_negatives_dict['other'])))  # + hard_negatives_dict['siblings']
                            random.shuffle(idx_list)
                            for idx in idx_list:
                                hn = hard_negatives_dict['other'][idx]
                                hn_text = neg_pairs['text_list'][hn[0]]
                                hn_text_hash = hashlib.md5(hn_text.encode("utf")).hexdigest()

                                if hn_text_hash in considered_text_hash[input_ex_anchor_hash]['neg']:
                                    continue

                                if idx >= len(hard_negatives_dict['other']):
                                    is_input_ex_hard_negative_from_siblings = True

                                # Avoid using hard negatives from the latest 128 concepts considered as anchors to generate input examples
                                if hn[1] == cid or hn[1] in train_samples_by_cid[cid]['ancestors'] or hn[1] in train_samples_by_cid[cid]['descendants'] or hn[1] in train_samples_by_cid[cid]['siblings']:
                                    continue

                                # Avoid duplication of hard negatives
                                considered_text_hash[input_ex_anchor_hash]['neg'].add(hn_text_hash)
                                input_ex_hard_negative = hn_text
                                input_ex_hard_negative_cid = hn[1]
                                break

                            if input_ex_hard_negative is None and len(hard_negatives_dict['other']) > 0:
                                considered_text_hash[input_ex_anchor_hash]['neg'] = set()

                        # print(f"       --> NEGATIVE TEXT: '{input_ex_hard_negative}'({input_ex_hard_negative_cid})")

                        stat_cid_with_train_ex.add(cid)

                        # Generate a training sample instance (i.e. InputExample)
                        if input_ex_hard_negative is None or not isinstance(input_ex_hard_negative, str) or len(input_ex_hard_negative.strip()) == 0:
                            # print(f"Attention, impossible to determine hard negative for the cid {cid} text '{input_ex_anchor}'")
                            input_example = InputExample(texts=[f'{input_ex_anchor}', f'{input_ex_positive}'])
                            input_example.anchor_positive_cid = cid
                            input_example.negative_cid = input_ex_hard_negative_cid
                            train_samples_by_cid[cid]['train_ex_list'].append(input_example)
                            stat_no_hard_neg = stat_no_hard_neg + 1
                            # print(f"       --> added example: ('{input_ex_anchor}', '{input_ex_positive}', '{input_ex_hard_negative}')")
                        else:
                            input_example = InputExample( texts=[f'{input_ex_anchor}', f'{input_ex_positive}', f'{input_ex_hard_negative}'])
                            input_example.anchor_positive_cid = cid
                            input_example.negative_cid = input_ex_hard_negative_cid
                            train_samples_by_cid[cid]['train_ex_list'].append(input_example)
                            stat_with_hard_neg = stat_with_hard_neg + 1
                            # print(f"       --> added example: ('{input_ex_anchor}', '{input_ex_positive}', '{input_ex_hard_negative}')")
                            stat_cid_with_neg_train_ex.add(input_ex_hard_negative_cid)
                            if is_input_ex_hard_negative_from_siblings is True:
                                stat_hard_neg_siblings = stat_hard_neg_siblings + 1
                            else:
                                stat_hard_neg_other = stat_hard_neg_other + 1

                        if len(train_samples_by_cid) % 500 == 0 and stat_printed_info is False:
                            stat_printed_info = True
                            print(
                                f"STATS: {sum([len(v['train_ex_list']) for k, v in train_samples_by_cid.items()])} training examples added, "
                                f"{stat_with_hard_neg} with hard negative ({stat_hard_neg_other} "
                                f"from other cid), {stat_no_hard_neg} without hard negative. "
                                f"{len(stat_cid_with_train_ex)} cids generated one or more anchor sentences, "
                                f"{len(stat_cid_with_neg_train_ex)} cids generated one or more hard "
                                f"negative sentences.")
            else:
                pass
                print(f"ATTENTION: cid {cid} has an empty set of alternative defiitions generated by synonym "
                      f"substitution for the original definition {text_dict['txt'] if isinstance(text_dict, dict) and 'txt' in text_dict else None}")

    # Populate list of training examples in train_samples
    train_samples = list()
    last_N_concept_ids = list()
    added_concept = True
    iteration_idx = 0
    while added_concept is True:
        iteration_idx = iteration_idx + 1
        added_concept = False

        cid_check_idx = 0
        added_training_examples_in_iteration = 0
        skip_negative_cid_check = False
        for cid, cid_dict in train_samples_by_cid.items():

            cid_check_idx = cid_check_idx + 1
            if cid_check_idx % 200 == 0:
                print(
                    f"Generating training examples... iteration: {iteration_idx}, cid checks performed: {cid_check_idx}, added new concept in iteration: {added_concept}")

            # Manage last_128_concept_ids LIFO queue (to be sure the last 128 concept IDs are not used tos elect hard negatives)
            last_N_concept_ids.append(cid)
            while len(last_N_concept_ids) > 128:
                last_N_concept_ids.pop()

            for input_ex in cid_dict['train_ex_list']:
                if input_ex is not None:

                    # Check if the hard_negative_cid of this input_ex is in the last_128_concept_ids
                    if skip_negative_cid_check is False and isinstance(input_example.negative_cid, str) and len(input_example.negative_cid) > 0 and input_example.negative_cid in last_N_concept_ids:
                        continue

                    if not hasattr(input_ex, 'already_considered') or input_ex.already_considered is not True:
                        train_samples.append(input_ex)

                        added_concept = True
                        added_training_examples_in_iteration = added_training_examples_in_iteration + 1
                        input_ex.already_considered = True
                        break

        if added_training_examples_in_iteration < 20:
            print(f"Added less than 20 examples in iteration, STOP - generating training examples... "
                  f"iteration: {iteration_idx}, cid checks performed: {cid_check_idx}, added new concept "
                  f"in iteration: {added_concept}")
            skip_negative_cid_check = True
            break

    print(f"Generated {len(train_samples)} training examples (anchor, positive, hard_negative)")

    return train_samples


sentence_transformer_model = None
evaluation_step_count = 0
# List to store the sentence similarity evaluation results across all calls of the sts_evaluation_callback
evaluation_result_sts_list = list()


def sts_evaluation_callback(score, epoch, steps):
    """
    Implementation of evaluation callback for Sentence Transformer fit procedure:
    https://www.sbert.net/docs/package_reference/sentence_transformer/SentenceTransformer.html#sentence_transformers.SentenceTransformer.fit
    This callback function is invoked after each evaluation while fitting a Sentence Transformer model.
    :param score: main evaluation score
    :param epoch: number of epoch (set to -10 to force evaluation)
    :param steps: number of steps
    :return:
    """
    global sentence_transformer_model
    global evaluation_step_count
    global evaluation_result_sts_list
    global config_dict

    print("Emptying cache memory (CUDA)...")
    if torch.cuda.is_available():
        # print("   --> Clearing CUDA cache...")
        torch.cuda.empty_cache()

    # Eval once every 15 callback calls
    evaluation_step_count = evaluation_step_count + 1
    if evaluation_step_count % 15 == 0 or epoch == -10:
        all_sts_evaluators_dict = evaluate_sts_datasets(sentence_transformer_model, epoch=epoch, steps=steps,
                                                        batch_size=128)
        # print(f"Loaded all STS evaluators: {json.dumps(all_sts_evaluators_dict, indent=4, sort_keys=True)}")
        evaluation_result_sts_list.append((epoch, steps, all_sts_evaluators_dict))

    # Print and store to file a table with the evaluation results of all evaluation callback calls
    rows_sts = list()
    for el in evaluation_result_sts_list:
        rows_sts.append([f'{el[0]}', f'{el[1]}',
                         f'{el[2]["BIOSSES__all"]["eval_spearman_cosine"]}',
                         f'{el[2]["BIOSSES__disease"]["eval_spearman_cosine"]}',
                         f'{el[2]["STS_12__all"]["eval_spearman_cosine"]}',
                         f'{el[2]["STS_12__disease"]["eval_spearman_cosine"]}',
                         f'{el[2]["STS_13__all"]["eval_spearman_cosine"]}',
                         f'{el[2]["STS_13__disease"]["eval_spearman_cosine"]}',
                         f'{el[2]["STS_14__all"]["eval_spearman_cosine"]}',
                         f'{el[2]["STS_14__disease"]["eval_spearman_cosine"]}',
                         f'{el[2]["STS_15__all"]["eval_spearman_cosine"]}',
                         f'{el[2]["STS_15__disease"]["eval_spearman_cosine"]}',
                         f'{el[2]["STS_16__all"]["eval_spearman_cosine"]}',
                         f'{el[2]["STS_16__disease"]["eval_spearman_cosine"]}'])

    print("\nEVALUATION RESULT TABLE - STS:")
    table_sts = tabulate(rows_sts, headers=['Epoch', 'Step',
                                            'BIOSSES (all)', 'BIOSSES (dis)',
                                            'STS_12 (all)', 'STS_12 (dis)',
                                            'STS_13 (all)', 'STS_13 (dis)',
                                            'STS_14 (all)', 'STS_14 (dis)',
                                            'STS_15 (all)', 'STS_15 (dis)',
                                            'STS_16 (all)', 'STS_16 (dis)'])

    print(table_sts)

    print(f"CONFIG DICT: {config_dict}\n")

    # Dump evaluation file
    if evaluation_step_count % 15 == 0 or epoch == -10:
        eval_file_name = os.path.join(constant_config.EVALUATION_RESULT_PATH,
                                      f"{config_dict['execution_id']}__eval_e{epoch}_step{evaluation_step_count}.eval")
        print(f"Storing evaluation results after {evaluation_step_count} steps of epoch {epoch} to file: {eval_file_name}...")
        with io.open(eval_file_name, 'w', encoding='utf8') as f:
            for k, v in config_dict.items():
                f.write(f'{k}: {v}\n')
            f.write('\n\n')
            f.write(table_sts + "\n\n")


if __name__ == '__main__':

    # COMMAND LINE ARGUMENT 1: sentence transformer base model identifier, to perform ontological knowledge infusion on
    # One of: sapbert_cls, pubmedbert_mean, pubmedbert_cls, gist, gtebase
    st_model = None
    if len(sys.argv) > 1 and isinstance(sys.argv[1], str):
        st_model = sys.argv[1].strip().lower()

    # COMMAND LINE ARGUMENT 2: name of the CSV file with synthetic definitions generated by running the script
    # synth_data_gen.generate_synth_data and stored in the folder constant_config.SYNTHETIC_DATA_OUTPUT_FOLDER_PATH
    name_of_synthetic_definitions_csv = None
    if len(sys.argv) > 2 and isinstance(sys.argv[2], str):
        name_of_synthetic_definitions_csv = sys.argv[2].strip()
    synthetic_definitions_file_path = os.path.join(constant_config.SYNTHETIC_DATA_OUTPUT_FOLDER_PATH,
                                                   name_of_synthetic_definitions_csv)
    my_file = Path(synthetic_definitions_file_path)
    if not my_file.is_file():
        print(f"Attention, the synthetic definitions file {name_of_synthetic_definitions_csv} does not exist in the "
              f"folder {constant_config.SYNTHETIC_DATA_OUTPUT_FOLDER_PATH}.")
        exit(1)

    sentence_embedding_LLM_ids = ["pubmedbert_mean", "pubmedbert_cls", "sapbert_cls", "gist", "gtebase"]
    if st_model not in sentence_embedding_LLM_ids:
        print(f"Attention, the name of the embedding-LLM to infuse ontological knowledge in is not in {sentence_embedding_LLM_ids}.")
        exit(1)

    # Load MONDO disease ontology
    onto_dict = load_mondo_onto_dictionary()

    # Set-up device for sentence transformer fine-tuning
    device = 'cpu'
    if torch.cuda.is_available():
        device = 'cuda'
    config_dict['device'] = device
    # if torch.backends.mps.is_available():
    #     device = 'mps'
    print(f"MODEL DEVICE: {device}, torch version: {torch.__version__}")

    # Reference to the transformer to fine-tune
    sentence_transformer_model = None

    # Name of the training examples pickle object file where to store training examples selecting positive pairs by
    # concept-synonym substitution and hard negative pairs by picking the text embedding that is: (i) most similar to
    # the embedding of texts of the positive pair; (ii) describing a concept that is not ancestor or descendant of the
    # considered concept
    training_examples_file_name = f"exp1_training_examples_{st_model}.pk"

    # Determine the name of the Chroma DB embedding database where to store all concept definitions to perform
    # nearest neighbours embedding searches
    chroma_db_name = f"mondo_gpt35def_{st_model}"

    # Set batch size for sentence transformer fine-tuning
    config_dict['batch_size'] = 24

    # True to enable training data shuffle
    config_dict['shuffle_data'] = "true"

    # Instantiate the sentence-transformer model
    if st_model == "sapbert_cls":
        # SapBERT model trained with triplet loss, CLS token, max-input-length 512 tokens
        config_dict['pooling_mode'] = 'cls'
        word_embedding_model = models.Transformer('cambridgeltl/SapBERT-from-PubMedBERT-fulltext')
        pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),
                                       pooling_mode_mean_tokens=False, pooling_mode_cls_token=True)
        sentence_transformer_model = SentenceTransformer(modules=[word_embedding_model, pooling_model], device=device)

    if st_model == "pubmedbert_mean":
        # Previously named "PubMedBERT (abstracts + full text)", BERT model pretrained from scratch using abstracts
        # from PubMed and full-text articles from PubMedCentral, text lowercase, max-input-length 512 tokens
        config_dict['pooling_mode'] = 'mean'
        word_embedding_model = models.Transformer('microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext')
        pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),
                                       pooling_mode_mean_tokens=True)
        sentence_transformer_model = SentenceTransformer(modules=[word_embedding_model, pooling_model], device=device)

    if st_model == "pubmedbert_cls":
        # Previously named "PubMedBERT (abstracts + full text)", BERT model pretrained from scratch using abstracts
        # from PubMed and full-text articles from PubMedCentral, text lowercase, max-input-length 512 tokens
        config_dict['pooling_mode'] = 'cls'
        word_embedding_model = models.Transformer('microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext')
        pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),
                                       pooling_mode_mean_tokens=False, pooling_mode_cls_token=True)
        sentence_transformer_model = SentenceTransformer(modules=[word_embedding_model, pooling_model], device=device)

    if st_model == "gist":
        # avsolatorio/GIST-Embedding-v0 - text lowercase, max-input-length 512 tokens
        config_dict['pooling_mode'] = 'cls'
        sentence_transformer_model_id = "avsolatorio/GIST-Embedding-v0"
        sentence_transformer_model = SentenceTransformer(sentence_transformer_model_id, trust_remote_code=True,
                                                         device=device)

    if st_model == "gtebase":
        # thenlper/gte-base - text lowercase, max-input-length 512 tokens
        config_dict['pooling_mode'] = 'mean'
        sentence_transformer_model_id = "thenlper/gte-base"
        sentence_transformer_model = SentenceTransformer(sentence_transformer_model_id, trust_remote_code=True,
                                                         device=device)

    print("EXECUTION DATA:")
    config_dict['execution_id'] = datetime.now().strftime(f"%Y_%m_%d__%H_%M_%S__exp1_{st_model}")
    config_dict['st_model'] = f"{st_model}"
    config_dict['chroma_db_name'] = chroma_db_name
    config_dict['training_examples_file_name'] = training_examples_file_name
    print(f"   --> st_model: {st_model}")
    print(f"   --> chroma_db_name: {chroma_db_name}")
    print(f"   --> training_examples_file_name: {training_examples_file_name}")

    # Checking arguments
    if sentence_transformer_model is None:
        print(f"Attention, impossible to instantiate the embedding-LLM {st_model}!")
        exit(1)

    if chroma_db_name is None:
        print("Attention, impossible to determine a valid name of Chroma DB collection!")
        exit(1)

    if training_examples_file_name is None:
        print("Attention, impossible to determine a valid name for the training examples pickle object file!")
        exit(1)

    # Perform initial evaluation of the non-fine-tuned sentence transformer model (with id defined by
    # the command-line-argument st_model variable value)
    sts_evaluation_callback(-10.0, -10, -10)

    # Load synthetic definitions from the CSV file generated by means of the synth_data_gen.generate_synth_data script
    # and stored in the constant_config.SYNTHETIC_DATA_OUTPUT_FOLDER_PAT
    gpt35_synthetic_defs, _ = load_definition_spreadsheet(definition_csv_full_path=synthetic_definitions_file_path)

    # Load positive and negative pairs
    positive_pairs, negative_pairs = generate_pairs(gpt35_synthetic_defs, onto_dict, sentence_transformer_model, chroma_db_name)

    # Load training examples to infuse ontological knowledge in embedding-LLM
    # (all training examples, once generated are stored in the file full path training_examples_path_pickle)
    training_examples_path_pickle = os.path.join(base_path_pickle, training_examples_file_name)
    if os.path.isfile(training_examples_path_pickle):
        print(f"Loading training examples from pickle file {training_examples_path_pickle}...")
        file = open(training_examples_path_pickle, 'rb')
        train_samples = pickle.load(file)
        file.close()

        print(f"Loaded {len(train_samples)} training samples (anchor, positive, hard_negative)")
    else:
        print(f"Loading training examples and then storing to pickle file {training_examples_path_pickle}...")

        train_samples = generate_training_examples(positive_pairs, negative_pairs)

        file = open(training_examples_path_pickle, 'wb')
        pickle.dump(train_samples, file)
        file.close()

    print(f"Loaded {len(train_samples)} input training examples (anchor, positive, hard_negative)...")

    # Start training and evaluation
    train_dataloader = None
    train_loss = None

    # Setting configuration parameters for sentence transformer fine-tuning
    batch_sz = config_dict['batch_size'] if 'batch_size' in config_dict else 16
    shuffle_data = False if 'shuffle_data' in config_dict and isinstance(config_dict['shuffle_data'], str) and config_dict['shuffle_data'].strip().lower() == "false" else True

    config_dict['warmup_steps'] = 16620
    config_dict['loss'] = {'name': 'MultipleNegativesRankingLoss', 'shuffle_data': shuffle_data, 'batch_size': batch_sz, 'scale': 20.0, 'similarity_fct': 'cos_sim'}
    train_dataloader = DataLoader(train_samples, shuffle=shuffle_data, batch_size=batch_sz)
    train_loss = losses.MultipleNegativesRankingLoss(model=sentence_transformer_model, scale=20.0)

    config_dict['evaluator_metric'] = f'{EVALUATORS_STS.BIOSSES_ALL}'
    evaluator_inst = get_STS_evaluator(eval_id=EVALUATORS_STS.BIOSSES_ALL, batch_size=128)

    config_dict['evaluation_steps'] = 30
    config_dict['weight_decay'] = 1e-4
    config_dict['optimizer_class'] = torch.optim.AdamW
    config_dict['optimizer_params'] = {"lr": 1e-8}
    config_dict['scheduler'] = 'warmupconstant'
    config_dict['max_grad_norm'] = 1
    config_dict['epochs'] = 2

    # Perform ontological knowledge infusion by fine-tuning the embedding-LLM, contextually evaluating it
    # against BIOSSES and SemEval Sentence Similarity 2012, 2013, 2014, 2015, and 2016
    # (through the sts_evaluation_callback callback)
    sentence_transformer_model.fit(
        train_objectives=[(train_dataloader, train_loss)],
        epochs=config_dict['epochs'],
        callback=sts_evaluation_callback,
        evaluator=evaluator_inst,
        evaluation_steps=config_dict['evaluation_steps'],
        weight_decay=config_dict['weight_decay'],
        max_grad_norm=config_dict['max_grad_norm'],
        optimizer_class=config_dict['optimizer_class'],
        optimizer_params=config_dict['optimizer_params'],
        scheduler=config_dict['scheduler'],
        warmup_steps=config_dict['warmup_steps']
    )

    # To enable the storage / checkpointing of the fine-tuned model the following parameters of the fit method can
    # be specified:
    # checkpoint_path – folder to save checkpoints during training
    # checkpoint_save_steps – will save a checkpoint after so many steps
    # checkpoint_save_total_limit – total number of checkpoints to store
